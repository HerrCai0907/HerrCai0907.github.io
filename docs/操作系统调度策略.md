# 调度策略

## FIFO 先到先得

- 简单直观
- 平均相应时间过长
- 短任务不友好

## Shortest Job First 短任务有限

- 策略不公平，任务饿死
- 平均相应时间过长

## Preemptive Scheduing 抢占式调度

- 一个时间片后被切换到下一个任务
- 通过定时触发的时钟中断实现

### Round Robin 时间片轮转

- 公平，响应时间短
- 周转时间长
- 时间片长度
  - 过长导致响应变慢，退化为 FIFO
  - 过短导致上下文切换时间长

## 调度优先级

- 多级队列 Multi-Level Queue，一般优先级数字越低，优先级越高
- 多资源调度情况下，需要考虑优先级的选取
  - IO 绑定任务有较高的优先级 - 提高资源利用率
  - 用户指定的重要任务
  - 时延要求较高的任务
  - 等待时间过长的任务（公平性）
- 优先级反转
  - 高低优先级任务都使用独占资源（信号量互斥锁）
  - 低优先级任务占用资源 -> 高优先级任务阻塞

## 公平共享调度策略

- 用户占用份额是确定并且可计算的
- 优先级硬，高优先级必定先执行，份额与执行顺序无关

### Lottery Scheduling 彩票调度

每次调度时候，生成随机数，根据随机数选择任务

### Stride Scheduling 步幅调度

确定性的彩票调度

- Stride 任务一次执行增加的虚拟时间
- Pass 累计执行的虚拟时间

调度器在所有任务中选择 Pass 最少的任务，然后调度，并增加 Stride

## Completely Fair Scheduler 完全公平调度（Linux 默认调度策略）

- 每个 CPU 核心维护一个红黑树作为调度树
- 节点的 key 为虚拟时间 vruntime

### 调度策略

- The leftmost node of the scheduling tree is chosen (as it will have the lowest spent execution time), and sent for execution. 每次选取最左节点（key 最小）作为当前运行的任务
- If the process simply completes execution, it is removed from the system and scheduling tree. 如果任务执行完毕，将其从调度树中移除。
- If the process reaches its maximum execution time or is otherwise stopped (voluntarily or via interrupt) it is reinserted into the scheduling tree based on its newly spent execution time. 如果任务达到最大执行时间/自愿停止/中断，该任务将修改 vruntime 并重新插入调度树。
- The new leftmost node will then be selected from the tree, repeating the iteration. 再次选择新的节点。
- vruntime

  - [进程权重](#权重): 根据 nice 值进行索引, nice 值每上升或者下降 1，CPU 时间将减少约 10%
    - 假设存在 2 个 task，每个 task 时间片为 0.5。当其中 task A 的 nice 值增加 1，对应的权重为 1277，此时时间片分配比例为 task A = 1277 / (1277 +1024) = 0.555, task B = 1024 / (1277 + 1024) = 0.445。task A 的时间片增加了 10%，即 "10% effect"
    - 假设存在 4 个 task，每个 task 的时间片为 0.25。当其中 task A 的 nice 值增加 1，其时间片为分配比例 task A = 1277 / (1277 + 1024 \*3) = 0.2936，其他 task 为 0.2355
  - [初始化 vruntime](#vruntime-initializing): 使用 cfs_rq->min_vruntime 初始化 vruntime。 min_vruntime 的值在每次修改 vruntime 时同步更新。
  - [更新](#vruntime-update): vruntime += 实际运行时间（time process run) \* 1024 / 进程权重(load weight of this process)

- 算法复杂度
  - 使用额外指针缓存最左节点，因此选取任务 O(1)
  - 插入任务 O(n)

### 组调度策略

ref: [CFS group scheduling](https://lwn.net/Articles/240474/)

当系统中存在多个用户时，对进程实行 CFS 无法保证用户之间的公平性，因此 CFS 被扩展为支持组调度

CFS 并非直接调度进程，而是通过调度实体进行调度。默认情况下，调度实体为一个进程，因此，进程位于层次结构的顶部，并且每个进程都是独立调度的。但一个进程可以从主运行队列中删除并移动到另一个调度实体下，当该进程变为可运行时，它被放入与其父调度实体关联的运行队列中。当 CFS 选择下一个要运行的任务时，他会按照 vruntime 选择一个调度实体。如果该实体不是进程（它是更高级的一个调度实体），则 CFS 查看包含在该实体中的运行队列，直到找到一个实际的进程。当进程运行时，它的运行时统计数据一样会被收集，并向上传播，使得 CPU 使用率反映在每个级别上。

因此，系统可以为不同的用户创建一个调度实体，并将该用户的所有进程放在该调度实体。在该调度实体中再次进行公平调度

### 带宽控制

- CFS 带宽控制是一个 CONFIG_FAIR_GROUP_SCHED 扩展，它允许指定一个组或层次的最大 CPU 带宽。
- 一个组允许的带宽是用配额和周期指定的。在每个给定的”周期“（微秒）内，一个任务组被分配多达“配额”微秒的 CPU 时间。当 cgroup 中的线程可运行时，该配额以时间片段的方式被分配到每个 cpu 运行队列中。一旦所有的配额被分配，任何额外的配额请求将导致这些线程被限流。被限流的线程将不能再次运行，直到下一个时期的配额得到补充。
- 父子任务组中，子任务组的配额之和可以大于父任务组的配额，当父任务组的配额消耗完时，即使子任务组仍有配额，也不能运行。
- 使用突发特性可以用于防范我们低估任务组的执行时间，但会增加其他系统用户的干扰。

- cpu.cfs_quota_us：在一个时期内补充的运行时间（微秒）。
- cpu.cfs_period_us：一个周期的长度（微秒）。
- cpu.cfs_burst_us：最大累积运行时间（微秒）。
- cpu.stat: 输出节流统计数据
  - nr_periods：已经过去的执行间隔的数量。
  - nr_throttled: 该组已被节流/限制的次数。
  - throttled_time: 该组的实体被限流的总时间长度（纳秒）。
  - nr_bursts：突发发生的周期数。
  - burst_time: 任何 CPU 在各个时期使用超过配额的累计壁钟时间（纳秒）。

#### 带宽控制事例

1. 限制一个组的运行时间为 1 个 CPU 的 100%。如果周期是 250ms，配额也是 250ms，那么该组将每 250ms 获得价值 1 个 CPU 的运行时间。
   ```bash
   # echo 250000 > cpu.cfs_quota_us /_ quota = 250ms _/
   # echo 250000 > cpu.cfs_period_us /_ period = 250ms _/
   ```
2. 在多 CPU 机器上，将一个组的运行时间限制为 2 个 CPU 的 100%。在 500ms 周期和 1000ms 配额的情况下，该组每 500ms 可以获得 2 个 CPU 的运行时间。这里较大的周期允许增加突发能力。
   ```bash
   # echo 1000000 > cpu.cfs_quota_us /_ quota = 1000ms _/
   # echo 500000 > cpu.cfs_period_us /_ period = 500ms _/
   ```
3. 将一个组限制在 1 个 CPU 的 20%。在 50ms 周期内，10ms 配额将相当于 1 个 CPU 的 20%。通过在这里使用一个小的周期，我们以牺牲突发容量为代价来确保稳定的延迟响应。
   ```bash
    # echo 10000 > cpu.cfs_quota_us /_ quota = 10ms _/
    # echo 50000 > cpu.cfs_period_us /_ period = 50ms _/
   ```
4. 将一个组限制在 1 个 CPU 的 40%，并允许累积到 1 个 CPU 的 20%，如果已经累积了的话。在 50ms 周期内，20ms 配额将相当于 1 个 CPU 的 40%。而 10 毫秒的突发将相当于 1 个 CPU 的 20%。较大的缓冲区设置（不大于配额）允许更大的突发容量。
   ```bash
   # echo 20000 > cpu.cfs_quota_us /_ quota = 20ms _/
   # echo 50000 > cpu.cfs_period_us /_ period = 50ms _/
   # echo 10000 > cpu.cfs_burst_us /_ burst = 10ms _/
   ```

## 附录

##### 权重

```c
/*
 * Nice levels are multiplicative, with a gentle 10% change for every
 * nice level changed. I.e. when a CPU-bound task goes from nice 0 to
 * nice 1, it will get ~10% less CPU time than another CPU-bound task
 * that remained on nice 0.
 *
 * The "10% effect" is relative and cumulative: from _any_ nice level,
 * if you go up 1 level, it's -10% CPU usage, if you go down 1 level
 * it's +10% CPU usage. (to achieve that we use a multiplier of 1.25.
 * If a task goes up by ~10% and another task goes down by ~10% then
 * the relative distance between them is ~25%.)
 */
const int sched_prio_to_weight[40] = {
 /* -20 */     88761,     71755,     56483,     46273,     36291,
 /* -15 */     29154,     23254,     18705,     14949,     11916,
 /* -10 */      9548,      7620,      6100,      4904,      3906,
 /*  -5 */      3121,      2501,      1991,      1586,      1277,
 /*   0 */      1024,       820,       655,       526,       423,
 /*   5 */       335,       272,       215,       172,       137,
 /*  10 */       110,        87,        70,        56,        45,
 /*  15 */        36,        29,        23,        18,        15,
};
```

##### vruntime initializing

```c
_do_fork()
--> p = copy_process(NULL, trace, NUMA_NO_NODE, args)
    --> retval = sched_fork(clone_flags, p)
        --> p->sched_class->task_fork(p)       // task_fork_fair()
            --> se->vruntime = curr->vruntime  // se is child, curr is parent
            --> place_entity(cfs_rq, se, 1)
                --> se->vruntime = max(se->vruntime, cfs_rq->min_vruntime+slice)
            --> se->vruntime -= cfs_rq->min_vruntime      // (1)
--> wake_up_new_task(p)
    --> activate_task(rq, p, ENQUEUE_NOCLOCK)
        --> enqueue_task(rq, p, flags)  // enqueue_task_fair()
            --> enqueue_entity(cfs_rq, se, flags)
                --> se->vruntime += cfs_rq->min_vruntime  // (2)
```

##### vruntime update

```c
static void update_curr(struct cfs_rq *cfs_rq) {
  u64 now = rq_clock_task(rq_of(cfs_rq));
  delta_exec = now - curr->exec_start;
  curr->vruntime += calc_delta_fair(delta_exec, curr);
}
static inline u64 calc_delta_fair(u64 delta, struct sched_entity *se) {
	if (unlikely(se->load.weight != NICE_0_LOAD)) delta = __calc_delta(delta, NICE_0_LOAD, &se->load);
	return delta;
}
// delta_exec * weight / lw.weight
static u64 __calc_delta(u64 delta_exec, unsigned long weight, struct load_weight *lw);
```
